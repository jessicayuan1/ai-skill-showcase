{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bbde3e6",
   "metadata": {},
   "source": [
    "# Michael Liu - AI Skills Showcase\n",
    "Hi, I'm Michael, I'm an Honours Mathematics Student at the University of Waterloo. Outside of school, I coach tennis and I'm a distance runner. Over the summer, I really got into machine learning. I took a few courses on YouTube on scikit-learn, PyTorch, SQL, Pandas, etc. While I am a Mathematics major, I want to make a difference in healthcare which is why I chose Project See-DR as my top choice. \n",
    "\n",
    "This is my AI Showcase for my application to Project See-DR. I'm creating a CNN model using PyTorch to accuractely predict hand-drawn numbers from the MNIST dataset. The custom CNN model contains 2 convolutional layers and then 2 linear layers. Model achieved 99.10% on training set and 99.36% on the testing set. \n",
    "\n",
    "---\n",
    "\n",
    "Notebook Order\n",
    "1. Loading Required Libraries\n",
    "    * `!pip install -r requirements.txt` to download required libraries\n",
    "2. Loading datasets from PyTorch datasets\n",
    "    * Loading the MNIST dataset from PyTorch \n",
    "    * The dataset contains 60,000 training and 10,000 testing images of hand-drawn digits 0-9\n",
    "3. Viewing 2 images\n",
    "4. Setting up DataLoaders for training\n",
    "    * Model is trained using DataLoaders with batch size 32 and shuffling\n",
    "    * Allows model to update weights multiple times per epoch\n",
    "5. Model Architecture, Loss, Accuracy, Optimizer\n",
    "    * Custom CNN Model built\n",
    "    * Model starts with 2 layers of `nn.Conv2d()` Filter Layer -> `nn.ReLU()` Non-Linear Activation -> `nn.MaxPool2d()` Spacial Size Decrease\n",
    "    * `nn.CrossEntropyLoss()` as loss function as this problem is multiclassification\n",
    "    * `torch.optim.Adam()` as optimization function with 0.001 learning rate\n",
    "6. Train-Test Loop\n",
    "    * Trained model on 7 epochs\n",
    "    * Acheived > 99% accuracy on the test set\n",
    "7. View 2 predictions on the Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9c5fd0",
   "metadata": {},
   "source": [
    "### 1. Load Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c99c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install -r requirements.txt to download required libraries\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#Device Agnostic Code/GPU acceleration -> mps is only for Silicon Macs, cuda requires NVIDIA GPU\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca5e09f",
   "metadata": {},
   "source": [
    "### 2. Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc51845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tranformation (Convert to Tensor)\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "#Load Datasets from PyTorch datasets\n",
    "train_set = datasets.MNIST(root = './data', train = True, transform = transform, download = True)\n",
    "test_set = datasets.MNIST(root = './data', train = False, transform = transform, download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bfdda3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set), len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1935d728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 5\n"
     ]
    }
   ],
   "source": [
    "img, label = train_set[0]\n",
    "print(img.shape, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d5966f",
   "metadata": {},
   "source": [
    "### 3. View 2 Images from the Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6aa69bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (5, 3))\n",
    "\n",
    "#First Image\n",
    "img1, label1 = train_set[0]\n",
    "ax[0].imshow(img1[0], cmap = \"gray\")\n",
    "ax[0].set_title(f\"Label: {label1}\")\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "#Second Image\n",
    "img2, label2 = train_set[1]\n",
    "ax[1].imshow(img2[0], cmap = \"gray\")\n",
    "ax[1].set_title(f\"Label: {label2}\")\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d11f45",
   "metadata": {},
   "source": [
    "### 4. Setup DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a24cee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model in batches. Allows model to update weights more often\n",
    "train_loader = DataLoader(train_set, batch_size = 32, shuffle = True, drop_last = True)\n",
    "test_loader  = DataLoader(test_set, batch_size = 1000, shuffle = False, drop_last = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed191c2e",
   "metadata": {},
   "source": [
    "### 5. Model Architecture, Loss Function, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b43296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #Feature Extraction/Convolutional Layers\n",
    "        self.convolution = nn.Sequential(\n",
    "            #Starting Size [32 (batch size), 1 (channels), 28 (height), 28 (width)]\n",
    "            nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3, stride = 1, padding = 1), #Upscale from 1 \n",
    "            nn.ReLU(), #Non-linear activation function\n",
    "            nn.MaxPool2d((2, 2)), #Spacial size reduction\n",
    "\n",
    "            # [32, 32, 14, 14]\n",
    "            nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2))\n",
    "            # [32, 64, 7, 7]\n",
    "        )\n",
    "        #Classification (Fully Connected Layers)\n",
    "        self.classifier = nn.Sequential(\n",
    "            # [32, 64, 7, 7]\n",
    "            nn.Flatten(), #Flatten into 64*7*7 by 1 tensor\n",
    "            # [32, 3136]\n",
    "            nn.Linear(in_features = 3136, out_features = 128),\n",
    "            # [32, 128]\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4), #Turn off some neurons to prevent overfitting\n",
    "            nn.Linear(in_features = 128, out_features = 10) #Downsize to number of classes\n",
    "            # [32, 10]\n",
    "        )\n",
    "        #Model Pipeline \n",
    "        self.order = nn.Sequential(\n",
    "            self.convolution,\n",
    "            self.classifier\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward Pass Function Override\"\"\"\n",
    "        return self.order(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8774f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the model and move to device\n",
    "model = MNISTClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3ecbc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy, Loss, and Optimization Functions\n",
    "def accuracy_function(pred: torch.Tensor, true: torch.Tensor) -> float:\n",
    "    \"\"\"Calculates classification accuracy as a percentage.\"\"\"\n",
    "    correct = torch.eq(pred, true).sum().item()\n",
    "    return correct / len(pred) * 100\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss() #Cross Entropy loss for multiclass classification. Takes logits as input\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3100488",
   "metadata": {},
   "source": [
    "### 6. Train-Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da9bba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_loop(\n",
    "    model: torch.nn.Module,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    epochs: int,\n",
    "    optimization_function: torch.optim.Optimizer,\n",
    "    accuracy_function: callable,\n",
    "    loss_function: torch.nn.Module,\n",
    "    device: str\n",
    ") -> None: \n",
    "    \"\"\"Runs `epoch` number of training and testing loops for a model. Prints accuracy and loss every epoch.\"\"\"\n",
    "    torch.manual_seed(11)\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch: {epoch} =================================\")\n",
    "        #Training Loop\n",
    "        model.train() #Set to train mode\n",
    "        train_loss_total, train_acc_total = 0, 0 #Keep track of total loss and total acc, then divide by number of batches at end\n",
    "        #Loop through training dataloader\n",
    "        for X_batch, y_batch in train_dataloader:\n",
    "            #Move batch to device\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            #Forward Pass\n",
    "            y_train_pred_logits = model(X_batch)\n",
    "            #Loss Calculation\n",
    "            loss = loss_function(y_train_pred_logits, y_batch)\n",
    "            train_loss_total += loss.item()\n",
    "            #Backpropagation to update weights\n",
    "            optimization_function.zero_grad()\n",
    "            loss.backward()\n",
    "            #Gradient Descent\n",
    "            optimization_function.step()\n",
    "            #Calculate accuracy\n",
    "            accuracy = accuracy_function(y_train_pred_logits.argmax(dim = 1), y_batch)\n",
    "            train_acc_total += accuracy\n",
    "        #Device total accuracy and loss by size of dataloader\n",
    "        train_acc = train_acc_total / len(train_dataloader)\n",
    "        train_loss = train_loss_total / len(train_dataloader)\n",
    "        print(f\"Train Loss: {train_loss} | Train Accuracy: {train_acc}\")\n",
    "\n",
    "        #Testing Loop\n",
    "        model.eval() #Set to eval mode, untrack gradients\n",
    "        test_loss_total, test_accuracy_total = 0, 0\n",
    "        with torch.inference_mode():\n",
    "            for X_batch, y_batch in test_dataloader:\n",
    "                #Move to device\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                #Forward Pass\n",
    "                y_test_pred_logits = model(X_batch)\n",
    "                # Loss\n",
    "                loss = loss_function(y_test_pred_logits, y_batch)\n",
    "                test_loss_total += loss.item()\n",
    "                # Accuracy\n",
    "                accuracy = accuracy_function(y_test_pred_logits.argmax(dim = 1), y_batch)\n",
    "                test_accuracy_total += accuracy\n",
    "        #Divide totals by length of dataloader\n",
    "        test_acc = test_accuracy_total / len(test_dataloader)\n",
    "        test_loss = test_loss_total / len(test_dataloader)\n",
    "        print(f\"Test Loss: {test_loss} | Test Accuracy: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c00b37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 =================================\n",
      "Train Loss: 0.20956429180999597 | Train Accuracy: 93.45333333333333\n",
      "Test Loss: 0.062066939659416676 | Test Accuracy: 97.97\n",
      "Epoch: 1 =================================\n",
      "Train Loss: 0.07836587504784887 | Train Accuracy: 97.69833333333334\n",
      "Test Loss: 0.03989974912256002 | Test Accuracy: 98.65\n",
      "Epoch: 2 =================================\n",
      "Train Loss: 0.057724378549757725 | Train Accuracy: 98.23833333333333\n",
      "Test Loss: 0.026541224075481297 | Test Accuracy: 99.06\n",
      "Epoch: 3 =================================\n",
      "Train Loss: 0.04628414956366566 | Train Accuracy: 98.57333333333334\n",
      "Test Loss: 0.03109415147919208 | Test Accuracy: 98.9\n",
      "Epoch: 4 =================================\n",
      "Train Loss: 0.03665421998932822 | Train Accuracy: 98.89833333333333\n",
      "Test Loss: 0.026531986147165298 | Test Accuracy: 99.1\n",
      "Epoch: 5 =================================\n",
      "Train Loss: 0.031816906777649034 | Train Accuracy: 99.01333333333334\n",
      "Test Loss: 0.02446080628433265 | Test Accuracy: 99.24\n",
      "Epoch: 6 =================================\n",
      "Train Loss: 0.028972473676273754 | Train Accuracy: 99.10166666666667\n",
      "Test Loss: 0.022100149863399567 | Test Accuracy: 99.35999999999999\n"
     ]
    }
   ],
   "source": [
    "#Run the training and testing loop for 5 epochs\n",
    "train_test_loop(\n",
    "    model = model,\n",
    "    train_dataloader = train_loader,\n",
    "    test_dataloader = test_loader,\n",
    "    epochs = 7,\n",
    "    optimization_function = optimizer,\n",
    "    accuracy_function = accuracy_function,\n",
    "    loss_function = loss_function,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d2a32e",
   "metadata": {},
   "source": [
    "### 7. View 2 Predictions on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0189ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Set model to evaluation mode and turn off gradient tracking\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    #Pick 2 samples from the test set\n",
    "    img1, label1 = test_set[0]\n",
    "    img2, label2 = test_set[1]\n",
    "\n",
    "    #Forward pass\n",
    "    out1 = model(img1.unsqueeze(0).to(device)) #Add expected batch dimension and move to device\n",
    "    out2 = model(img2.unsqueeze(0).to(device))\n",
    "    pred1 = out1.argmax(dim = 1).item()\n",
    "    pred2 = out2.argmax(dim = 1).item()\n",
    "\n",
    "#Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize = (5, 3))\n",
    "\n",
    "ax[0].imshow(img1[0], cmap = \"gray\")\n",
    "ax[0].set_title(f\"True: {label1} | Pred: {pred1}\")\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "ax[1].imshow(img2[0], cmap = \"gray\")\n",
    "ax[1].set_title(f\"True: {label2} | Pred: {pred2}\")\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
